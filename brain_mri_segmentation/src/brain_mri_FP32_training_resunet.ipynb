{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob2\n",
    "import random\n",
    "import cv2\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import *\n",
    "from losses import *\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.abspath('../dataset/lgg-mri-segmentation/kaggle_3m/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_PATH + '/data.csv'))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob2.glob(DATASET_PATH + '/**/*.tif'))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = [x.split('/')[-2] for x in images]\n",
    "patient_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(patient_id, images)), columns=['patient_id', 'image_path'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = df[~df['image_path'].str.contains(\"mask\")] # if have not mask\n",
    "df_masks = df[df['image_path'].str.contains(\"mask\")]# if have mask\n",
    "\n",
    "# File path line length images for later sorting\n",
    "BASE_LEN = len(DATASET_PATH + '/TCGA_DU_6408_19860521/TCGA_DU_6408_19860521_')\n",
    "END_IMG_LEN = 4\n",
    "END_MASK_LEN = 9\n",
    "\n",
    "# Data sorting\n",
    "imgs = sorted(df_imgs[\"image_path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\n",
    "masks = sorted(df_masks[\"image_path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n",
    "\n",
    "# Sorting check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe\n",
    "brain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n",
    "                         \"image_path\": imgs,\n",
    "                         \"mask_path\": masks\n",
    "                        })\n",
    "\n",
    "def has_mask(mask_path):\n",
    "    value = np.max(cv2.imread(mask_path))\n",
    "    if value > 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "brain_df['mask'] = brain_df['mask_path'].apply(lambda x: has_mask(x))\n",
    "brain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(brain_df)):\n",
    "    if cv2.imread(brain_df.mask_path[i]).max() > 0:\n",
    "        break\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cv2.imread(brain_df.mask_path[i]));\n",
    "plt.title('Tumor Location')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cv2.imread(brain_df.image_path[i]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,2, figsize=(16,26))\n",
    "count = 0\n",
    "for x in range(6):\n",
    "  i = random.randint(0, len(brain_df)) # select a random index\n",
    "  axs[count][0].title.set_text(\"Brain MRI\") # set title\n",
    "  axs[count][0].imshow(cv2.imread(brain_df.image_path[i])) # show MRI \n",
    "  axs[count][1].title.set_text(\"Mask - \" + str(brain_df['mask'][i])) # plot title on the mask (0 or 1)\n",
    "  axs[count][1].imshow(cv2.imread(brain_df.mask_path[i])) # Show corresponding mask\n",
    "  count += 1\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "i = 0\n",
    "fig,axs = plt.subplots(12,3, figsize=(20,50))\n",
    "for mask in brain_df['mask']:\n",
    "    if (mask==1):\n",
    "        img = io.imread(brain_df.image_path[i])\n",
    "        axs[count][0].title.set_text(\"Brain MRI\")\n",
    "        axs[count][0].imshow(img)\n",
    "        \n",
    "        mask = io.imread(brain_df.mask_path[i])\n",
    "        axs[count][1].title.set_text(\"Mask\")\n",
    "        axs[count][1].imshow(mask, cmap='gray')\n",
    "        \n",
    "        img[mask==255] = (0,255,150)  # change pixel color at the position of mask\n",
    "        axs[count][2].title.set_text(\"MRI with Mask\")\n",
    "        axs[count][2].imshow(img)\n",
    "        count +=1\n",
    "    i += 1\n",
    "    if (count==12):\n",
    "        break\n",
    "        \n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
    "brain_df_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test, train and val sets\n",
    "\n",
    "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
    "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "\n",
    "train_ids = list(X_train.image_path)\n",
    "train_mask = list(X_train.mask_path)\n",
    "\n",
    "val_ids = list(X_val.image_path)\n",
    "val_mask= list(X_val.mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataGenerator(train_ids, train_mask)\n",
    "val_data = DataGenerator(val_ids, val_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compling model and callbacks functions\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
    "seg_model.compile(optimizer = adam, \n",
    "                  loss = focal_tversky, \n",
    "                  metrics = [tversky, dice_coef]\n",
    "                 )\n",
    "#callbacks\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=20\n",
    "                             )\n",
    "# save the best model with lower validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"ResUNet-segModel-weights.hdf5\", \n",
    "                               verbose=1, \n",
    "                               save_best_only=True\n",
    "                              )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = seg_model.fit(train_data, \n",
    "                  epochs = 60, \n",
    "                  validation_data = val_data,\n",
    "                  callbacks = [checkpointer, earlystopping, reduce_lr]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(h.history['loss']);\n",
    "plt.plot(h.history['val_loss']);\n",
    "plt.title(\"SEG Model focal tversky Loss\");\n",
    "plt.ylabel(\"focal tversky loss\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(h.history['dice_coef']);\n",
    "plt.plot(h.history['val_dice_coef']);\n",
    "plt.title(\"SEG Model Dice Coef score\");\n",
    "plt.ylabel(\"Dice  Coeff\");\n",
    "plt.xlabel(\"Epochs\");\n",
    "plt.legend(['train', 'val']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = list(X_test.image_path)\n",
    "test_mask = list(X_test.mask_path)\n",
    "test_data = DataGenerator(test_ids, test_mask)\n",
    "_, tv, dice = seg_model.evaluate(test_data)\n",
    "print(\"Segmentation tversky is {:.2f}%\".format(tv*100))\n",
    "print(\"Segmentation Dice is {:.2f}\".format(dice))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
