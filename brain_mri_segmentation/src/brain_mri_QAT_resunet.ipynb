{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob2\n",
    "import random\n",
    "import cv2\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from model import *\n",
    "from losses import *\n",
    "from data_generator import DataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = os.path.abspath('../dataset/lgg-mri-segmentation/kaggle_3m/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATASET_PATH + '/data.csv'))\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = sorted(glob2.glob(DATASET_PATH + '/**/*.tif'))\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_id = [x.split('/')[-2] for x in images]\n",
    "patient_id[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(patient_id, images)), columns=['patient_id', 'image_path'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imgs = df[~df['image_path'].str.contains(\"mask\")] # if have not mask\n",
    "df_masks = df[df['image_path'].str.contains(\"mask\")]# if have mask\n",
    "\n",
    "# File path line length images for later sorting\n",
    "BASE_LEN = len(DATASET_PATH + '/TCGA_DU_6408_19860521/TCGA_DU_6408_19860521_')\n",
    "END_IMG_LEN = 4\n",
    "END_MASK_LEN = 9\n",
    "\n",
    "# Data sorting\n",
    "imgs = sorted(df_imgs[\"image_path\"].values, key=lambda x : int(x[BASE_LEN:-END_IMG_LEN]))\n",
    "masks = sorted(df_masks[\"image_path\"].values, key=lambda x : int(x[BASE_LEN:-END_MASK_LEN]))\n",
    "\n",
    "# Sorting check\n",
    "idx = random.randint(0, len(imgs)-1)\n",
    "print(\"Path to the Image:\", imgs[idx], \"\\nPath to the Mask:\", masks[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataframe\n",
    "brain_df = pd.DataFrame({\"patient_id\": df_imgs.patient_id.values,\n",
    "                         \"image_path\": imgs,\n",
    "                         \"mask_path\": masks\n",
    "                        })\n",
    "\n",
    "def has_mask(mask_path):\n",
    "    value = np.max(cv2.imread(mask_path))\n",
    "    if value > 0: \n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "brain_df['mask'] = brain_df['mask_path'].apply(lambda x: has_mask(x))\n",
    "brain_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization\n",
    "\n",
    "Please refer to the code provided in `brain_mri_FP32_training_resunet.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
    "brain_df_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating test, train and val sets\n",
    "\n",
    "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5)\n",
    "print(\"Train size is {}, valid size is {} & test size is {}\".format(len(X_train), len(X_val), len(X_test)))\n",
    "\n",
    "train_ids = list(X_train.image_path)\n",
    "train_mask = list(X_train.mask_path)\n",
    "\n",
    "val_ids = list(X_val.image_path)\n",
    "val_mask= list(X_val.mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = DataGenerator(train_ids, train_mask)\n",
    "val_data = DataGenerator(val_ids, val_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QAT Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
    "quantize_annotate_model = tfmot.quantization.keras.quantize_annotate_model\n",
    "quantize_scope = tfmot.quantization.keras.quantize_scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultBNQuantizeConfig(tfmot.quantization.keras.QuantizeConfig):\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return []\n",
    "    \n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return []\n",
    "    \n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        pass\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        pass\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return [tfmot.quantization.keras.quantizers.MovingAverageQuantizer(\n",
    "    num_bits=8, per_axis=False, symmetric=False, narrow_range=False)]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantization_to_batch_normalization(layer):\n",
    "    if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        return quantize_annotate_layer(layer, DefaultBNQuantizeConfig())\n",
    "    \n",
    "    return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading FP32 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_model = get_model()\n",
    "seg_model.load_weights('./ResUNet-segModel-weights.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making model Quantization Aware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_model = tf.keras.models.clone_model(\n",
    "                    seg_model,\n",
    "                    clone_function=apply_quantization_to_batch_normalization,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with quantize_scope(\n",
    "    {'DefaultBNQuantizeConfig': DefaultBNQuantizeConfig}):\n",
    "    # Use `quantize_apply` to actually make the model quantization aware.\n",
    "    quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best model with lower validation loss\n",
    "qaware_checkpointer = ModelCheckpoint(filepath=\"QAware_ResUNet-segModel-weights.hdf5\", \n",
    "                                verbose=1, \n",
    "                                save_best_only=True\n",
    "                            )\n",
    "\n",
    "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
    "\n",
    "quant_aware_model.compile(optimizer = adam, \n",
    "                  loss = focal_tversky, \n",
    "                  metrics = [tversky, dice_coef]\n",
    "                 )\n",
    "\n",
    "earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                              verbose=1, \n",
    "                              patience=20\n",
    "                             )\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              verbose=1,\n",
    "                              patience=10,\n",
    "                              min_delta=0.0001,\n",
    "                              factor=0.2\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_h = quant_aware_model.fit(train_data, \n",
    "                    epochs = 60, \n",
    "                    validation_data = val_data,\n",
    "                    callbacks = [qaware_checkpointer, earlystopping, reduce_lr]\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = list(X_test.image_path)\n",
    "test_mask = list(X_test.mask_path)\n",
    "test_data = DataGenerator(test_ids, test_mask)\n",
    "_, tv, dice = quant_aware_model.evaluate(test_data)\n",
    "print(\"Segmentation tversky is {:.2f}%\".format(tv*100))\n",
    "print(\"Segmentation Dice is {:.2f}\".format(dice))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting weights to INT8 and saving it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "quantized_tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('QAT_INT8_Brain_MRI_Segmentation.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
